{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"THECGAN_DM_F200_v3_DONE_7_12_19.ipynb","provenance":[{"file_id":"18GUFkUfH70YhxiOVs44R2eKOABbCvonF","timestamp":1575974322681},{"file_id":"1pr7TZ952-9p32zSUXoqgFWDa8aJZlc7J","timestamp":1575899443272},{"file_id":"19WsiUvG6YDr7EldCuZsoTBoPwxBy6V0F","timestamp":1575889819471},{"file_id":"1MM-0_7l_GJtTgCaKiRVlTv013ZqhM_XZ","timestamp":1575831621170},{"file_id":"1VViWJ_6bC5uMl69utKCaa_etLaS_SvE-","timestamp":1574158483100}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IbMJiBp3K1au","colab_type":"text"},"source":["## F200 Conditional GAN - 7/12/19\n","\n","As mentioned before, s1 and s2 are important characteristics to correctly model. Therefore the following script will create a conditional GAN, using s1 for dark matter at 50KeV and 200KeV"]},{"cell_type":"code","metadata":{"id":"-kvWzO3vR2iG","colab_type":"code","outputId":"e6e4281d-6318-4b21-9238-aa47cdf5c58b","executionInfo":{"status":"ok","timestamp":1579723313740,"user_tz":0,"elapsed":5921,"user":{"displayName":"Enrico Zammit","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFOVnZwKwdnqK8WIMopoEbv20zI_cQL3oBToD6AA=s64","userId":"14160691232459682112"}},"colab":{"base_uri":"https://localhost:8080/","height":257}},"source":["pip install uproot"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting uproot\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/c7/77d2f88dd7523992c9b6c3c785490d2ba0299ba09054190ce216fda7cf19/uproot-3.11.1-py2.py3-none-any.whl (114kB)\n","\r\u001b[K     |██▉                             | 10kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from uproot) (1.17.5)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.6/dist-packages (from uproot) (4.0.0)\n","Collecting uproot-methods>=0.7.0\n","  Downloading https://files.pythonhosted.org/packages/3c/39/7867f279a8ca8a67ae8ca56c371dda6cc8e05dc01ac614f05586c857dfe2/uproot_methods-0.7.2-py2.py3-none-any.whl\n","Collecting awkward<1.0,>=0.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f3/d86d52275cfe131692c89558a22187e40cf111485154affac74d7509ee43/awkward-0.12.19-py2.py3-none-any.whl (87kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n","\u001b[?25hInstalling collected packages: awkward, uproot-methods, uproot\n","Successfully installed awkward-0.12.19 uproot-3.11.1 uproot-methods-0.7.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aSmoCK1-nsrU","colab_type":"code","outputId":"deeebbf9-bcb9-4521-dd57-8e3216d9a67a","executionInfo":{"status":"ok","timestamp":1579723333691,"user_tz":0,"elapsed":19136,"user":{"displayName":"Enrico Zammit","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFOVnZwKwdnqK8WIMopoEbv20zI_cQL3oBToD6AA=s64","userId":"14160691232459682112"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VHQ_gVoroQzy","colab_type":"code","outputId":"07b34afe-18fb-44b6-fa47-7c500ac07fb3","executionInfo":{"status":"ok","timestamp":1579723336599,"user_tz":0,"elapsed":461,"user":{"displayName":"Enrico Zammit","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFOVnZwKwdnqK8WIMopoEbv20zI_cQL3oBToD6AA=s64","userId":"14160691232459682112"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd gdrive/My\\ Drive/dark_matter_7_12_19"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/dark_matter_7_12_19\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"58BmV9jWXWGC","colab_type":"text"},"source":["Here we will extract some root files, most will be used to train the GAN, then one will be used to 'validate' the GAN.\n","\n","Currently, we will use 50, 150, and 250 to train and 100 and 200 to validate."]},{"cell_type":"code","metadata":{"id":"sN4x00DZn3jy","colab_type":"code","colab":{}},"source":["import uproot\n","import pandas\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tree50 = uproot.open(\"dark_matter_runs_50kev.root\")[\"dstree\"]\n","tree100 = uproot.open(\"dark_matter_100kev_v1.root\")[\"dstree\"]\n","tree150 = uproot.open(\"dark_matter_runs_150kev.root\")[\"dstree\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ynJoaGiBLniI","colab_type":"text"},"source":["The Variable is input here to try to make the code reusable and as general as possible."]},{"cell_type":"code","metadata":{"id":"UPw1MbDlvCjB","colab_type":"code","colab":{}},"source":["#VARIABLE\n","var = \"f200like\"\n","rangemin = 0.5\n","rangemax = 0.8"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFvx_AGLoT46","colab_type":"code","outputId":"fdfcfacd-bdcb-4b7e-f464-797d2d2e0efb","executionInfo":{"status":"ok","timestamp":1579723361172,"user_tz":0,"elapsed":8610,"user":{"displayName":"Enrico Zammit","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFOVnZwKwdnqK8WIMopoEbv20zI_cQL3oBToD6AA=s64","userId":"14160691232459682112"}},"colab":{"base_uri":"https://localhost:8080/","height":307}},"source":["#For f200 multiply *100\n","train_DS_ene_50 = np.array(tree50.array(f\"{var}\"))\n","train_DS_ene_100 = np.array(tree100.array(f\"{var}\"))\n","train_DS_ene_150 = np.array(tree150.array(f\"{var}\"))\n","\n","train_var = [50., 100., 150.]\n","\n","e_50 = plt.hist(train_DS_ene_50, density = True, bins = 100, alpha = 0.8,color = \"blue\", label=r\"($var=\"+f\"{train_var[0]:.0f}\"+r\"~{\\rm KeV}$)\")\n","e_100 = plt.hist(train_DS_ene_100, density = True, bins = 100, alpha = 0.8,color = \"green\",label=r\"($var=\"+f\"{train_var[1]:.0f}\"+r\"~{\\rm KeV}$)\")\n","e_150 = plt.hist(train_DS_ene_150, density = True, bins = 100, alpha = 0.8,color = \"red\",label=r\"($var=\"+f\"{train_var[2]:.0f}\"+r\"~{\\rm KeV}$)\")\n","\n","plt.legend(loc=\"upper left\", fontsize=10)\n","plt.xlabel(\"f200\", size=14, labelpad=10)\n","plt.ylabel(r\"$\\rho\\left(x\\right)$\", size=14, labelpad=30, rotation=\"horizontal\")\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$\\\\rho\\\\left(x\\\\right)$')"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaYAAAEQCAYAAAD74tBrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW/gidk4AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"fADIRTnu-wFZ","colab_type":"code","colab":{}},"source":["num_train = int(1e3)\n","noise_size = 1000\n","\n","# Length needs to be followed through"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9e9VuLx-0Pn","colab_type":"code","outputId":"de771e06-905e-4cb0-e0e6-9ed8854b729d","executionInfo":{"status":"ok","timestamp":1579705123695,"user_tz":0,"elapsed":9535,"user":{"displayName":"Krishan Jethwa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC0ITjB5xwH-JB4xfUopBjBWHyQS5Fum7FRThVd=s64","userId":"05183645186253804341"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.layers     import BatchNormalization, Dense, Dropout, Input, LeakyReLU, Concatenate\n","from keras.models     import Model, Sequential\n","from keras.optimizers import Adam, SGD\n","\n","import keras.backend as K\n","d_do = 0.2\n","g_do = 0.2\n","g_nodes = 80\n","d_nodes = 100\n","#Input of GEN VALUE\n","d1_in = Input((1,))\n","d1 = Dense(d_nodes, activation=\"relu\")(d1_in)\n","d1 = Dropout(d_do)(d1)\n","\n","#Input of parameter = energy\n","hyper_in = Input((1,))\n","d2 = Dense(d_nodes, activation=\"relu\")(hyper_in)\n","d2 = Dropout(d_do)(d2)\n","\n","dc = Concatenate()([d1, d2])\n","dc = Dense(g_nodes , activation=\"relu\")(dc)\n","dc = Dropout(d_do)(dc)\n","dc = Dense(d_nodes , activation=\"relu\")(dc)\n","dc = Dropout(d_do)(dc)\n","dc = Dense(g_nodes , activation=\"relu\")(dc)\n","dc = LeakyReLU(0.2)(dc)\n","dc = Dropout(d_do)(dc)\n","dc = Dense(g_nodes , activation=\"relu\")(dc)\n","dc = LeakyReLU(0.2)(dc)\n","dc = Dropout(d_do)(dc)\n","dc = Dense(2, activation=\"softmax\")(dc)\n","\n","dc = Model(name=\"Discriminator\", inputs=[d1_in, hyper_in], outputs=[dc])\n","dc.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.0005, beta_1=0.3), metrics=[\"accuracy\"])\n","# 0.0005, beta_1=0.5\n","dc.summary()\n","\n","#INPUT OF NOISE TO GENERATOR\n","g1_in = Input((noise_size,))\n","g1 = Dense(g_nodes, activation=\"relu\")(g1_in)\n","g1 = Dropout(g_do)(g1)\n","g1 = BatchNormalization()(g1)\n","g1 = Dense(g_nodes, activation=\"relu\")(g1)\n","\n","#INPUT OF HYPERPARAM\n","g2 = Dense(g_nodes, activation=\"relu\")(hyper_in)\n","\n","gc = Concatenate()([g1, g2])\n","gc = BatchNormalization()(gc)\n","gc = Dropout(g_do)(gc)\n","gc = Dense(g_nodes, activation=\"relu\")(gc)\n","gc = Dropout(g_do)(gc)\n","g1 = Dense(g_nodes, activation=\"relu\")(g1)\n","gc = Dropout(g_do)(gc)\n","g1 = Dense(g_nodes, activation=\"relu\")(g1)\n","gc = Dense(1, activation=\"linear\")(gc)\n","\n","gc = Model(name=\"Generator\", inputs=[g1_in, hyper_in], outputs=[gc])\n","gc.summary()\n","\n","\n","gan_out = dc([gc([g1_in, hyper_in]), hyper_in])\n","gan = Model([g1_in, hyper_in], gan_out, name=\"GAN\")\n","dc.trainable = False\n","gan.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.0005, beta_1=0.3), metrics=[\"accuracy\"])\n","gan.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"Discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 100)          200         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 100)          200         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 100)          0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 200)          0           dropout_1[0][0]                  \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 80)           16080       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 80)           0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 100)          8100        dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 80)           8080        dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 80)           0           dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 80)           0           leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 80)           6480        dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 80)           0           dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 80)           0           leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 2)            162         dropout_6[0][0]                  \n","==================================================================================================\n","Total params: 39,302\n","Trainable params: 39,302\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"Generator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 80)           80080       input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 80)           0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 80)           320         dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 80)           6480        batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 80)           160         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 160)          0           dense_9[0][0]                    \n","                                                                 dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 160)          640         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 160)          0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 80)           12880       dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 80)           0           dense_11[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 80)           0           dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 1)            81          dropout_10[0][0]                 \n","==================================================================================================\n","Total params: 100,641\n","Trainable params: 100,161\n","Non-trainable params: 480\n","__________________________________________________________________________________________________\n","Model: \"GAN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 1000)         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","Generator (Model)               (None, 1)            100641      input_3[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","Discriminator (Model)           (None, 2)            39302       Generator[1][0]                  \n","                                                                 input_2[0][0]                    \n","==================================================================================================\n","Total params: 139,943\n","Trainable params: 100,161\n","Non-trainable params: 39,782\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-aAlsYLU_jCv","colab_type":"code","colab":{}},"source":["#  Train GAN\n","\n","epochs     = 1000\n","batch_size = 1000\n","rel_batch_size = 1\n","max_D_itrs_per_G_itr_e80 = 2\n","max_D_itrs_per_G_itr_e52 = 3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3epq64SRCYJ2","colab_type":"code","colab":{}},"source":["def plot_points_GAN (gen_data, train_data, epoch, batch_size, d_acc) :\n","\n","    #Needs to be changed depending on number of examples\n","    gen_class_length = int(gen_data.shape[0]/3)\n","    gen_data_1 = gen_data[:gen_class_length                    ,0]\n","    gen_data_2 = gen_data[gen_class_length  :2*gen_class_length,0]\n","    gen_data_3 = gen_data[2*gen_class_length:3*gen_class_length,0]\n","    tr_class_length = int(train_data.shape[0]/3)\n","    train_data_1 = train_data[:tr_class_length                   ,0]\n","    train_data_2 = train_data[tr_class_length  :2*tr_class_length,0]\n","    train_data_3 = train_data[2*tr_class_length:3*tr_class_length,0]\n","\n","\n","    fig = plt.figure(figsize=(15,5))\n","    fig.add_subplot(1, 2, 1)\n","    h0 = plt.hist(gen_data_115, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"blue\"  , density=True, label=r\"Generated data ($var=\"+f\"{train_var[0]:.0f}\"+r\"~{\\rm KeV}$)\")\n","    h1 = plt.hist(gen_data_130, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"purple\", density=True, label=r\"Generated data ($var=\"+f\"{train_var[1]:.0f}\"+r\"~{\\rm KeV}$)\")\n","    h2 = plt.hist(gen_data_145, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"red\"   , density=True, label=r\"Generated data ($var=\"+f\"{train_var[2]:.0f}\"+r\"~{\\rm KeV}$)\")\n","    plt.legend(loc=\"upper right\", fontsize=10)\n","    plt.xlabel(\"x\", size=14, labelpad=10)\n","    plt.ylabel(r\"$\\rho\\left(x\\right)$\", size=14, labelpad=30, rotation=\"horizontal\")\n","    plt.gca().set_xlim([range_min-0.1*range_width, range_max+0.1*range_width])\n","    #y_max = 1.5*np.max([max(h0[0]), max(h1[0]), max(h2[0])])\n","    y_max = 1\n","    if np.isnan(y_max) : y_max = 1.0\n","    plt.gca().set_ylim([0, y_max])\n","    plt.text(range_min+0.*1.1*range_width   , 0.88*y_max, \"Conditional\", size=14, style=\"italic\", weight=\"bold\")\n","    plt.text(range_min+0.*1.1*range_width   , 0.80*y_max, \"GAN test\", size=18, style=\"italic\", weight=\"bold\")\n","    plt.text(range_min+0.780*1.1*range_width, 0.68*y_max, f\"Epoch: {epoch}\")\n","    plt.text(range_min+0.713*1.1*range_width, 0.61*y_max, f\"Batch size: {gen_class_length}\")\n","    plt.text(range_min+0.810*1.1*range_width, 0.54*y_max, r\"$\\epsilon_{\\rm disc}$: \"+f\"{int(100.*d_acc)}%\")\n","    plt.subplots_adjust(left=0.18, right=0.98, top=0.95, bottom=0.15)\n","    fig.add_subplot(1, 2, 2)\n","    h0_2 = plt.hist(train_data_115, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"blue\"  , density=True, label=r\"Training data ($m=\"+f\"{train_var[0]:.0f}\"+r\"~{\\rm GeV}$)\")\n","    h1_2 = plt.hist(train_data_130, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"purple\", density=True, label=r\"Training data ($m=\"+f\"{train_var[1]:.0f}\"+r\"~{\\rm GeV}$)\")\n","    h2_2 = plt.hist(train_data_145, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"red\"   , density=True, label=r\"Training data ($m=\"+f\"{train_var[2]:.0f}\"+r\"~{\\rm GeV}$)\")\n","    plt.legend(loc=\"upper right\", fontsize=10)\n","    plt.xlabel(\"x\", size=14, labelpad=10)\n","    plt.gca().set_xlim([range_min-0.1*range_width, range_max+0.1*range_width])\n","    #y_max = 1.5*np.max([max(h0_2[0]), max(h1_2[0]), max(h2_2[0])])\n","    y_max = 1\n","    if np.isnan(y_max) : y_max = 1.0\n","    plt.gca().set_ylim([0, y_max])\n","    plt.text(range_min+0.780*1.1*range_width, 0.68*y_max, f\"Epoch: {epoch}\")\n","    plt.text(range_min+0.713*1.1*range_width, 0.61*y_max, f\"Batch size: {tr_class_length}\")\n","    plt.text(range_min+0.810*1.1*range_width, 0.54*y_max, r\"$\\epsilon_{\\rm disc}$: \"+f\"{int(100.*d_acc)}%\")\n","    plt.subplots_adjust(left=0.18, right=0.98, top=0.95, bottom=0.15)\n","    #plt.savefig(f\"out/1D_GAN_test/Train_epoch{epoch}.png\", dpi=96)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACzAy29n_ph8","colab_type":"code","outputId":"f4f9e9de-52da-4b62-965f-f7012e4e850b","executionInfo":{"status":"error","timestamp":1577974422943,"user_tz":-60,"elapsed":2408885,"user":{"displayName":"Enrico Zammit","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCFOVnZwKwdnqK8WIMopoEbv20zI_cQL3oBToD6AA=s64","userId":"14160691232459682112"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Ck_UlOcujDVvYolnGS6XMFu_eDat2SlC"}},"source":["#  Train GAN\n","range_min, range_max = 0, 70\n","range_width = 70\n","plot_resolution = 200\n","epochs     = 20000\n","batch_size = 1000\n","\n","real_loss = []\n","real_acc = []\n","epoch_no = []\n","\n","def update_batch_size (gen_DS, e) :\n","    global batch_size\n","    #batch_size = min(max(batch_size, 100+int((e+1)/10.)), num_train)\n","    \n","def get_noise () :\n","    hyperparams = np.concatenate([np.full(fill_value=train_var[0], shape=(batch_size, 1)),\n","                                  np.full(fill_value=train_var[1], shape=(batch_size, 1)),\n","                                  np.full(fill_value=train_var[2], shape=(batch_size, 1))])\n","    return np.random.normal(size=(3*batch_size, noise_size)), hyperparams\n","\n","def get_train_data () :\n","    batch_1 = train_DS_ene_50[np.random.randint(0, len(train_DS_ene_50), rel_batch_size*batch_size)].reshape(rel_batch_size*batch_size, 1)\n","    batch_2 = train_DS_ene_100[np.random.randint(0, len(train_DS_ene_100), rel_batch_size*batch_size)].reshape(rel_batch_size*batch_size, 1)\n","    batch_3 = train_DS_ene_150[np.random.randint(0, len(train_DS_ene_150), rel_batch_size*batch_size)].reshape(rel_batch_size*batch_size, 1)\n","    hyperparams = np.concatenate([np.full(fill_value=train_var[0], shape=(rel_batch_size*batch_size, 1)),\n","                                  np.full(fill_value=train_var[1], shape=(rel_batch_size*batch_size, 1)),\n","                                  np.full(fill_value=train_var[2], shape=(rel_batch_size*batch_size, 1))])\n","    return np.concatenate([batch_1, batch_2, batch_3]), hyperparams\n","  \n","epochs_saved = []\n","for e in range(epochs) :\n","    noise, noise_hyperparams    = get_noise()\n","    batch_DS, batch_hyperparams = get_train_data()\n","    gen_DS   = gc.predict([noise, noise_hyperparams])\n","    real_label  = np.array([[1., 0.] for i in range(3*rel_batch_size*batch_size)])\n","    fake_label  = np.array([[0., 1.] for i in range(3*batch_size)])\n","    train_label = np.array([[1., 0.] for i in range(3*batch_size)])\n","    X  = np.concatenate([batch_DS  , gen_DS    ])\n","    Xh = np.concatenate([batch_hyperparams  , noise_hyperparams    ])\n","    Y = np.concatenate([real_label, fake_label])\n","    W = np.concatenate([np.ones(shape=(batch_DS.shape[0],)), np.full(fill_value=rel_batch_size, shape=(gen_DS.shape[0],))])\n","    \n","    dc.trainable = True\n","    d_loss, d_acc = dc.train_on_batch([X, Xh], Y, sample_weight=W)\n","        \n","    noise, noise_hyperparams = get_noise()\n","    dc.trainable = False\n","    gan.train_on_batch([noise, noise_hyperparams], train_label)\n","    \n","    if e == 0 or (e+1) % 20 == 0 :\n","        noise, noise_hyperparams = get_noise()\n","        gen_DS = gc.predict([noise, noise_hyperparams])\n","        #plot_points_GAN(\n","        #            gen_DS,\n","        #            batch_DS,\n","        #            epoch=e+1, \n","        #            batch_size=batch_size, \n","        #            d_acc=dc.evaluate([X, Xh], Y, sample_weight=W, verbose=0)[1])\n","        e_50 = plt.hist(train_DS_ene_50, density = True, bins = 100, alpha = 0.4, color='blue', label=r\"($var=\"+f\"{train_var[0]:.0f}\"+r\"~{\\rm KeV}$)\")\n","        e_150 = plt.hist(train_DS_ene_100, density = True, bins = 100, alpha = 0.4, color='red', label=r\"($var=\"+f\"{train_var[1]:.0f}\"+r\"~{\\rm KeV}$)\")\n","        e_250 = plt.hist(train_DS_ene_150, density = True, bins = 100, alpha = 0.4, color='green', label=r\"($var=\"+f\"{train_var[2]:.0f}\"+r\"~{\\rm KeV}$)\")\n","\n","        gen_class_length = int(gen_DS.shape[0]/3)\n","        gen_data_115 = gen_DS[:gen_class_length                    ,0]\n","        gen_data_130 = gen_DS[gen_class_length  :2*gen_class_length,0]\n","        gen_data_145 = gen_DS[2*gen_class_length:3*gen_class_length,0]\n","        \n","        gen_50 = plt.hist(gen_data_115, density = True, bins = 100, color='blue')\n","        gen_150 = plt.hist(gen_data_130, density = True, bins = 100, color='red')\n","        gen_250 = plt.hist(gen_data_145, density = True, bins = 100, color='green')\n","\n","        plt.legend(loc=\"upper right\", fontsize=10)\n","        plt.xlabel(\"x\", size=14, labelpad=10)\n","        plt.ylabel(r\"$\\rho\\left(x\\right)$\", size=14, labelpad=30, rotation=\"horizontal\")\n","        plt.title(f\"1D CGAN at Epoch {e+1} and batch size {batch_size}\")\n","        #plt.text(50,0.85,f\"Epochs: {epochs}\")\n","        #plt.text(50,0.75,f\"Batch Size: {batch_size}\")\n","        plt.show()\n","        epoch_no.append(e)\n","        real_loss.append(d_loss)\n","        real_acc.append(d_acc)\n","\n","        update_batch_size(gen_DS, e)\n","        epochs_saved.append(e+1)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"_8YzuNjPk2G9","colab_type":"code","colab":{}},"source":["del epoch_no[0]\n","del real_loss[0]\n","del real_acc[0]\n","h3 = plt.plot(epoch_no,real_loss, color = 'blue', label = \"Loss\")\n","h4 = plt.plot(epoch_no,real_acc, color = 'orange', label = \"Accuracy\")\n","plt.xlabel(\"Epoch number\", size=14, labelpad=10)\n","plt.ylabel(\"Loss\", size=14, labelpad=30, rotation=\"vertical\")\n","plt.title(f\"Disciminator variables with batch size {batch_size} for s1 vs s2\")\n","plt.legend(loc=\"upper right\", fontsize=10)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_Giw65dEwZM","colab_type":"code","colab":{}},"source":["mass = [200]\n","tree200 = uproot.open(\"dark_matter_runs_200kev.root\")[\"dstree\"]\n","train_DS_ene_200 = np.array(tree200.array(f\"{var}\"))*1\n","\n","hyperparams = np.full(fill_value=mass, shape=(100000, 1))\n","z = np.random.normal(size=(10000, noise_size))\n","datapoints = gc.predict([z, hyperparams])[:,0]\n","s1_true = plt.hist(train_DS_ene_200, density = True, bins = 100, alpha = 1, color='red', label = 'G4 Data')\n","s1_gen = plt.hist(datapoints, density = True, bins = 100, alpha = 0.4, color='red', label = 'Generated Data')\n","\n","\n","plt.legend(loc=\"upper right\", fontsize=10)\n","plt.xlabel(var, size=14, labelpad=10)\n","plt.ylabel(r\"$\\rho\\left(x\\right)$\", size=14, labelpad=30, rotation=\"horizontal\")\n","#plt.title(\"Comparing our CGAN with unseen G4 Data for 50keV\")\n","\n","#s1_diff = s1_true[0] - s1_gen[0]\n","\n","#sum_s1_diff = 0\n","#for i in range(len(s1_diff)):\n"," # sum_s1_diff += abs(s1_diff[i])\n","\n","#plt.text(60,0.43,f\"Loss: {round(sum_s1_diff)}\")\n","\n","plt.show()\n","\n","print(f\"          MASS = {mass}\")\n","print(f\"GENERATED MEAN = {np.mean(datapoints):.1f}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"guJlaJXpRTcD","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKULPeeaRd8_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}