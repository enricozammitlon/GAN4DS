{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CGAN_DM_S1_DROPOUT.ipynb","provenance":[{"file_id":"1MM-0_7l_GJtTgCaKiRVlTv013ZqhM_XZ","timestamp":1574955307769},{"file_id":"1VViWJ_6bC5uMl69utKCaa_etLaS_SvE-","timestamp":1574158483100}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IbMJiBp3K1au","colab_type":"text"},"source":["# S1 Conditional GAN\n","\n","As mentioned before, s1 and s2 are important characteristics to correctly model. Therefore the following script will create a conditional GAN, using s1 for dark matter at 50KeV and 200KeV"]},{"cell_type":"code","metadata":{"id":"-kvWzO3vR2iG","colab_type":"code","outputId":"0931bf9b-fd35-439a-834a-0bf17fdb52be","executionInfo":{"status":"ok","timestamp":1574958176720,"user_tz":0,"elapsed":6407,"user":{"displayName":"Krishan Jethwa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC0ITjB5xwH-JB4xfUopBjBWHyQS5Fum7FRThVd=s64","userId":"05183645186253804341"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["pip install uproot"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: uproot in /usr/local/lib/python3.6/dist-packages (3.10.12)\n","Requirement already satisfied: awkward<1.0,>=0.12.0 in /usr/local/lib/python3.6/dist-packages (from uproot) (0.12.17)\n","Requirement already satisfied: uproot-methods>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from uproot) (0.7.1)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.6/dist-packages (from uproot) (3.1.1)\n","Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from uproot) (1.17.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aSmoCK1-nsrU","colab_type":"code","outputId":"6e763e5a-867e-4af7-c21e-e4d895672ce0","executionInfo":{"status":"ok","timestamp":1574958176725,"user_tz":0,"elapsed":6381,"user":{"displayName":"Krishan Jethwa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC0ITjB5xwH-JB4xfUopBjBWHyQS5Fum7FRThVd=s64","userId":"05183645186253804341"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VHQ_gVoroQzy","colab_type":"code","outputId":"d66dbb28-6d1a-4abe-90c9-568c0c0dcd51","executionInfo":{"status":"ok","timestamp":1574958176727,"user_tz":0,"elapsed":6349,"user":{"displayName":"Krishan Jethwa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC0ITjB5xwH-JB4xfUopBjBWHyQS5Fum7FRThVd=s64","userId":"05183645186253804341"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd gdrive/My\\ Drive/test_run"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/test_run\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"58BmV9jWXWGC","colab_type":"text"},"source":["Here we will extract some root files, most will be used to train the GAN, then one will be used to 'validate' the GAN.\n","\n","Currently, we will use 50, 150, and 250 to train and 100 and 200 to validate."]},{"cell_type":"code","metadata":{"id":"sN4x00DZn3jy","colab_type":"code","colab":{}},"source":["import uproot\n","import pandas\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","tree50 = uproot.open(\"darkmatter_test_run_v5.root\")[\"dstree\"]\n","tree100 = uproot.open(\"darkmatter_test_run_v7.root\")[\"dstree\"]\n","tree150 = uproot.open(\"darkmatter_test_run_v8.root\")[\"dstree\"]\n","tree200 = uproot.open(\"darkmatter_test_run_v6.root\")[\"dstree\"]\n","tree250 = uproot.open(\"darkmatter_test_run_v9.root\")[\"dstree\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ynJoaGiBLniI","colab_type":"text"},"source":["The Variable is input here to try to make the code reusable and as general as possible."]},{"cell_type":"code","metadata":{"id":"UPw1MbDlvCjB","colab_type":"code","colab":{}},"source":["#VARIABLE\n","var = \"s1ene\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFvx_AGLoT46","colab_type":"code","outputId":"104ac29b-01b0-4b50-caf6-0a19cdbff972","executionInfo":{"status":"ok","timestamp":1574958178372,"user_tz":0,"elapsed":7955,"user":{"displayName":"Krishan Jethwa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC0ITjB5xwH-JB4xfUopBjBWHyQS5Fum7FRThVd=s64","userId":"05183645186253804341"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["\n","train_DS_ene_50 = np.array(tree50.array(f\"{var}\"))\n","train_DS_ene_100 = np.array(tree100.array(f\"{var}\"))\n","train_DS_ene_150 = np.array(tree150.array(f\"{var}\"))\n","train_DS_ene_200 = np.array(tree200.array(f\"{var}\"))\n","train_DS_ene_250 = np.array(tree250.array(f\"{var}\"))\n","\n","e_50 = plt.hist(train_DS_ene_50,range = (0,70), density = True, bins = 205, alpha = 0.8)\n","e_150 = plt.hist(train_DS_ene_150,range = (0,70), density = True, bins = 205, alpha = 0.8)\n","e_250 = plt.hist(train_DS_ene_250,range = (0,70), density = True, bins = 205, alpha = 0.8)\n"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsNAlqREWuiQ1wkKXpEZY6JLUiH8FfEIQGgtJihAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"fADIRTnu-wFZ","colab_type":"code","colab":{}},"source":["num_train = int(1e5)\n","noise_size = 100\n","\n","# Length needs to be followed through\n","train_var = [50., 150., 250.]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9e9VuLx-0Pn","colab_type":"code","outputId":"0eb7f093-2e10-4166-a1e0-78e6a5e111d1","executionInfo":{"status":"ok","timestamp":1574958180043,"user_tz":0,"elapsed":9604,"user":{"displayName":"Krishan Jethwa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC0ITjB5xwH-JB4xfUopBjBWHyQS5Fum7FRThVd=s64","userId":"05183645186253804341"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.layers     import BatchNormalization, Dense, Dropout, Input, LeakyReLU, Concatenate\n","from keras.models     import Model, Sequential\n","from keras.optimizers import Adam, SGD\n","\n","import keras.backend as K\n","\n","#Input of GEN VALUE\n","d1_in = Input((1,))\n","d1 = Dense(50, activation=\"relu\")(d1_in)\n","d1 = Dropout(0.2)(d1)\n","\n","#Input of parameter = energy\n","hyper_in = Input((1,))\n","d2 = Dense(50, activation=\"relu\")(hyper_in)\n","d2 = Dropout(0.4)(d2)\n","\n","dc = Concatenate()([d1, d2])\n","dc = Dense(50 , activation=\"relu\")(dc)\n","dc = Dropout(0.4)(dc)\n","dc = Dense(50 , activation=\"relu\")(dc)\n","dc = Dropout(0.4)(dc)\n","dc = Dense(50 , activation=\"relu\")(dc)\n","dc = Dense(50 , activation=\"relu\")(dc)\n","dc = Dense(2, activation=\"softmax\")(dc)\n","\n","dc = Model(name=\"Discriminator\", inputs=[d1_in, hyper_in], outputs=[dc])\n","dc.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.0005, beta_1=0.3), metrics=[\"accuracy\"])\n","# 0.0005, beta_1=0.5\n","dc.summary()\n","\n","#INPUT OF NOISE TO GENERATOR\n","g1_in = Input((noise_size,))\n","g1 = Dense(50, activation=\"relu\")(g1_in)\n","g1 = Dropout(0.4)(g1)\n","g1 = BatchNormalization()(g1)\n","g1 = Dense(50, activation=\"relu\")(g1)\n","\n","#INPUT OF HYPERPARAM\n","g2 = Dense(50, activation=\"relu\")(hyper_in)\n","\n","gc = Concatenate()([g1, g2])\n","gc = Dropout(0.4)(gc)\n","gc = Dense(50, activation=\"relu\")(gc)\n","gc = Dropout(0.4)(gc)\n","gc = Dense(50, activation=\"relu\")(gc)\n","gc = Dense(1, activation=\"linear\")(gc)\n","\n","gc = Model(name=\"Generator\", inputs=[g1_in, hyper_in], outputs=[gc])\n","gc.summary()\n","\n","\n","gan_out = dc([gc([g1_in, hyper_in]), hyper_in])\n","gan = Model([g1_in, hyper_in], gan_out, name=\"GAN\")\n","dc.trainable = False\n","#ADAM LEARNING RATE CHANGED\n","gan.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.0005, beta_1=0.3), metrics=[\"accuracy\"])\n","gan.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"Discriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 50)           100         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 50)           100         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 50)           0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 50)           0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 100)          0           dropout_1[0][0]                  \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 50)           5050        concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 50)           0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 50)           2550        dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 50)           0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 50)           2550        dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 50)           2550        dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 2)            102         dense_6[0][0]                    \n","==================================================================================================\n","Total params: 13,002\n","Trainable params: 13,002\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"Generator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 50)           5050        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 50)           0           dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 50)           200         dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 50)           2550        batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 50)           100         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 100)          0           dense_9[0][0]                    \n","                                                                 dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 100)          0           concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 50)           5050        dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 50)           0           dense_11[0][0]                   \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 50)           2550        dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","dense_13 (Dense)                (None, 1)            51          dense_12[0][0]                   \n","==================================================================================================\n","Total params: 15,551\n","Trainable params: 15,451\n","Non-trainable params: 100\n","__________________________________________________________________________________________________\n","Model: \"GAN\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1)            0                                            \n","__________________________________________________________________________________________________\n","Generator (Model)               (None, 1)            15551       input_3[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","Discriminator (Model)           (None, 2)            13002       Generator[1][0]                  \n","                                                                 input_2[0][0]                    \n","==================================================================================================\n","Total params: 28,553\n","Trainable params: 15,451\n","Non-trainable params: 13,102\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-aAlsYLU_jCv","colab_type":"code","colab":{}},"source":["#  Train GAN\n","\n","epochs     = 1000\n","batch_size = 100\n","rel_batch_size = 1\n","max_D_itrs_per_G_itr_e80 = 2\n","max_D_itrs_per_G_itr_e52 = 3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3epq64SRCYJ2","colab_type":"code","colab":{}},"source":["def plot_points_GAN (gen_data, train_data, epoch, batch_size, d_acc) :\n","\n","    #Needs to be changed depending on number of examples\n","    gen_class_length = int(gen_data.shape[0]/3)\n","    gen_data_1 = gen_data[:gen_class_length                    ,0]\n","    gen_data_2 = gen_data[gen_class_length  :2*gen_class_length,0]\n","    gen_data_3 = gen_data[2*gen_class_length:3*gen_class_length,0]\n","    tr_class_length = int(train_data.shape[0]/3)\n","    train_data_1 = train_data[:tr_class_length                   ,0]\n","    train_data_2 = train_data[tr_class_length  :2*tr_class_length,0]\n","    train_data_3 = train_data[2*tr_class_length:3*tr_class_length,0]\n","\n","\n","    fig = plt.figure(figsize=(15,5))\n","    fig.add_subplot(1, 2, 1)\n","    h0 = plt.hist(gen_data_115, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"blue\"  , density=True, label=r\"Generated data ($var=\"+f\"{train_var[0]:.0f}\"+r\"~{\\rm KeV}$)\")\n","    h1 = plt.hist(gen_data_130, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"purple\", density=True, label=r\"Generated data ($var=\"+f\"{train_var[1]:.0f}\"+r\"~{\\rm KeV}$)\")\n","    h2 = plt.hist(gen_data_145, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"red\"   , density=True, label=r\"Generated data ($var=\"+f\"{train_var[2]:.0f}\"+r\"~{\\rm KeV}$)\")\n","    plt.legend(loc=\"upper right\", fontsize=10)\n","    plt.xlabel(\"x\", size=14, labelpad=10)\n","    plt.ylabel(r\"$\\rho\\left(x\\right)$\", size=14, labelpad=30, rotation=\"horizontal\")\n","    plt.gca().set_xlim([range_min-0.1*range_width, range_max+0.1*range_width])\n","    #y_max = 1.5*np.max([max(h0[0]), max(h1[0]), max(h2[0])])\n","    y_max = 1\n","    if np.isnan(y_max) : y_max = 1.0\n","    plt.gca().set_ylim([0, y_max])\n","    plt.text(range_min+0.*1.1*range_width   , 0.88*y_max, \"Conditional\", size=14, style=\"italic\", weight=\"bold\")\n","    plt.text(range_min+0.*1.1*range_width   , 0.80*y_max, \"GAN test\", size=18, style=\"italic\", weight=\"bold\")\n","    plt.text(range_min+0.780*1.1*range_width, 0.68*y_max, f\"Epoch: {epoch}\")\n","    plt.text(range_min+0.713*1.1*range_width, 0.61*y_max, f\"Batch size: {gen_class_length}\")\n","    plt.text(range_min+0.810*1.1*range_width, 0.54*y_max, r\"$\\epsilon_{\\rm disc}$: \"+f\"{int(100.*d_acc)}%\")\n","    plt.subplots_adjust(left=0.18, right=0.98, top=0.95, bottom=0.15)\n","    fig.add_subplot(1, 2, 2)\n","    h0_2 = plt.hist(train_data_115, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"blue\"  , density=True, label=r\"Training data ($m=\"+f\"{train_var[0]:.0f}\"+r\"~{\\rm GeV}$)\")\n","    h1_2 = plt.hist(train_data_130, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"purple\", density=True, label=r\"Training data ($m=\"+f\"{train_var[1]:.0f}\"+r\"~{\\rm GeV}$)\")\n","    h2_2 = plt.hist(train_data_145, bins=np.linspace(range_min, range_max, 1+int(range_width/plot_resolution)), color=\"red\"   , density=True, label=r\"Training data ($m=\"+f\"{train_var[2]:.0f}\"+r\"~{\\rm GeV}$)\")\n","    plt.legend(loc=\"upper right\", fontsize=10)\n","    plt.xlabel(\"x\", size=14, labelpad=10)\n","    plt.gca().set_xlim([range_min-0.1*range_width, range_max+0.1*range_width])\n","    #y_max = 1.5*np.max([max(h0_2[0]), max(h1_2[0]), max(h2_2[0])])\n","    y_max = 1\n","    if np.isnan(y_max) : y_max = 1.0\n","    plt.gca().set_ylim([0, y_max])\n","    plt.text(range_min+0.780*1.1*range_width, 0.68*y_max, f\"Epoch: {epoch}\")\n","    plt.text(range_min+0.713*1.1*range_width, 0.61*y_max, f\"Batch size: {tr_class_length}\")\n","    plt.text(range_min+0.810*1.1*range_width, 0.54*y_max, r\"$\\epsilon_{\\rm disc}$: \"+f\"{int(100.*d_acc)}%\")\n","    plt.subplots_adjust(left=0.18, right=0.98, top=0.95, bottom=0.15)\n","    #plt.savefig(f\"out/1D_GAN_test/Train_epoch{epoch}.png\", dpi=96)\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACzAy29n_ph8","colab_type":"code","outputId":"67367eb8-d470-434f-e376-1205ea4b4708","executionInfo":{"status":"error","timestamp":1574958585753,"user_tz":0,"elapsed":4383,"user":{"displayName":"Krishan Jethwa","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC0ITjB5xwH-JB4xfUopBjBWHyQS5Fum7FRThVd=s64","userId":"05183645186253804341"}},"colab":{"base_uri":"https://localhost:8080/","height":692}},"source":["#  Train GAN\n","range_min, range_max = 0, 70\n","range_width = 70\n","plot_resolution = 200\n","epochs     = 10000\n","batch_size = 1000\n","\n","real_loss = []\n","real_acc = []\n","epoch_no = []\n","\n","def update_batch_size (gen_DS, e) :\n","    global batch_size\n","    #batch_size = min(max(batch_size, 100+int((e+1)/10.)), num_train)\n","    \n","def get_noise () :\n","    hyperparams = np.concatenate([np.full(fill_value=train_var[0], shape=(batch_size, 1)),\n","                                  np.full(fill_value=train_var[1], shape=(batch_size, 1)),\n","                                  np.full(fill_value=train_var[2], shape=(batch_size, 1))])\n","    return np.random.normal(size=(3*batch_size, noise_size)), hyperparams\n","\n","def get_train_data () :\n","    batch_1 = train_DS_ene_50[np.random.randint(0, len(train_DS_ene_50), rel_batch_size*batch_size)].reshape(rel_batch_size*batch_size, 1)\n","    batch_2 = train_DS_ene_150[np.random.randint(0, len(train_DS_ene_150), rel_batch_size*batch_size)].reshape(rel_batch_size*batch_size, 1)\n","    batch_3 = train_DS_ene_250[np.random.randint(0, len(train_DS_ene_250), rel_batch_size*batch_size)].reshape(rel_batch_size*batch_size, 1)\n","    hyperparams = np.concatenate([np.full(fill_value=train_var[0], shape=(rel_batch_size*batch_size, 1)),\n","                                  np.full(fill_value=train_var[1], shape=(rel_batch_size*batch_size, 1)),\n","                                  np.full(fill_value=train_var[2], shape=(rel_batch_size*batch_size, 1))])\n","    return np.concatenate([batch_1, batch_2, batch_3]), hyperparams\n","  \n","epochs_saved = []\n","for e in range(epochs) :\n","    noise, noise_hyperparams    = get_noise()\n","    batch_DS, batch_hyperparams = get_train_data()\n","    gen_DS   = gc.predict([noise, noise_hyperparams])\n","    real_label  = np.array([[1., 0.] for i in range(3*rel_batch_size*batch_size)])\n","    fake_label  = np.array([[0., 1.] for i in range(3*batch_size)])\n","    train_label = np.array([[1., 0.] for i in range(3*batch_size)])\n","    X  = np.concatenate([batch_DS  , gen_DS    ])\n","    Xh = np.concatenate([batch_hyperparams  , noise_hyperparams    ])\n","    Y = np.concatenate([real_label, fake_label])\n","    W = np.concatenate([np.ones(shape=(batch_DS.shape[0],)), np.full(fill_value=rel_batch_size, shape=(gen_DS.shape[0],))])\n","    \n","    dc.trainable = True\n","    d_loss, d_acc = dc.train_on_batch([X, Xh], Y, sample_weight=W)\n","        \n","    noise, noise_hyperparams = get_noise()\n","    dc.trainable = False\n","    gan.train_on_batch([noise, noise_hyperparams], train_label)\n","    \n","    if e == 0 or (e+1) % 200 == 0 :\n","        noise, noise_hyperparams = get_noise()\n","        gen_DS = gc.predict([noise, noise_hyperparams])\n","        #plot_points_GAN(\n","        #            gen_DS,\n","        #            batch_DS,\n","        #            epoch=e+1, \n","        #            batch_size=batch_size, \n","        #            d_acc=dc.evaluate([X, Xh], Y, sample_weight=W, verbose=0)[1])\n","        e_50 = plt.hist(train_DS_ene_50,range = (0,70), density = True, bins = 205, alpha = 0.4, color='blue', label=r\"($var=\"+f\"{train_var[0]:.0f}\"+r\"~{\\rm KeV}$)\")\n","        e_150 = plt.hist(train_DS_ene_150,range = (0,70), density = True, bins = 205, alpha = 0.4, color='red', label=r\"($var=\"+f\"{train_var[1]:.0f}\"+r\"~{\\rm KeV}$)\")\n","        e_250 = plt.hist(train_DS_ene_250,range = (0,70), density = True, bins = 205, alpha = 0.4, color='green', label=r\"($var=\"+f\"{train_var[2]:.0f}\"+r\"~{\\rm KeV}$)\")\n","\n","        gen_class_length = int(gen_DS.shape[0]/3)\n","        gen_data_115 = gen_DS[:gen_class_length                    ,0]\n","        gen_data_130 = gen_DS[gen_class_length  :2*gen_class_length,0]\n","        gen_data_145 = gen_DS[2*gen_class_length:3*gen_class_length,0]\n","        \n","        gen_50 = plt.hist(gen_data_115,range = (0,70), density = True, bins = 205, color='blue')\n","        gen_150 = plt.hist(gen_data_130,range = (0,70), density = True, bins = 205, color='red')\n","        gen_250 = plt.hist(gen_data_145,range = (0,70), density = True, bins = 205, color='green')\n","\n","        plt.legend(loc=\"upper right\", fontsize=10)\n","        plt.xlabel(\"x\", size=14, labelpad=10)\n","        plt.ylabel(r\"$\\rho\\left(x\\right)$\", size=14, labelpad=30, rotation=\"horizontal\")\n","        plt.title(f\"1D CGAN at Epoch {e+1} and batch size {batch_size}\")\n","        #plt.text(50,0.85,f\"Epochs: {epochs}\")\n","        #plt.text(50,0.75,f\"Batch Size: {batch_size}\")\n","        plt.show()\n","        epoch_no.append(e)\n","        real_loss.append(d_loss)\n","        real_acc.append(d_acc)\n","\n","        update_batch_size(gen_DS, e)\n","        epochs_saved.append(e+1)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/lib/histograms.py:908: RuntimeWarning: invalid value encountered in true_divide\n","  return n/db/n.sum(), bin_edges\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAEgCAYAAADyhqeBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ccb249883d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_hyperparams\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mget_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mbatch_DS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_hyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgen_DS\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_hyperparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mreal_label\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrel_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mfake_label\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"_8YzuNjPk2G9","colab_type":"code","colab":{}},"source":["del epoch_no[0]\n","del real_loss[0]\n","del real_acc[0]\n","\n","h3 = plt.plot(epoch_no,real_loss, color = 'blue', label = \"Loss\")\n","h4 = plt.plot(epoch_no,real_acc, color = 'orange', label = \"Accuracy\")\n","plt.xlabel(\"Epoch number\", size=14, labelpad=10)\n","plt.ylabel(\"Accuracy/Loss\", size=14, labelpad=30, rotation=\"vertical\")\n","plt.title(f\"Disciminator variables with batch size {batch_size} for s1 vs s2\")\n","plt.legend(loc=\"upper right\", fontsize=10)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_Giw65dEwZM","colab_type":"code","colab":{}},"source":["mass = 200\n","\n","hyperparams = np.full(fill_value=mass, shape=(100000, 1))\n","z = np.random.normal(size=(10000, noise_size))\n","datapoints = gc.predict([z, hyperparams])[:,0]\n","s1_true = plt.hist(train_DS_ene_200,range = (40,70), density = True, bins = 205, alpha = 1, color='red', label = 'G4 Data')\n","s1_gen = plt.hist(datapoints,range = (40,70), density = True, bins = 205, alpha = 0.4, color='red', label = 'Generated Data')\n","\n","\n","plt.legend(loc=\"upper right\", fontsize=10)\n","plt.xlabel(\"s1 energy\", size=14, labelpad=10)\n","plt.ylabel(r\"$\\rho\\left(x\\right)$\", size=14, labelpad=30, rotation=\"horizontal\")\n","plt.title(\"Comparing our CGAN with unseen G4 Data for 200KeV\")\n","\n","s1_diff = s1_true[0] - s1_gen[0]\n","\n","sum_s1_diff = 0\n","for i in range(len(s1_diff)):\n","  sum_s1_diff += abs(s1_diff[i])\n","\n","plt.text(60,0.43,f\"Loss: {round(sum_s1_diff)}\")\n","\n","plt.show()\n","\n","print(f\"          MASS = {mass}\")\n","print(f\"GENERATED MEAN = {np.mean(datapoints):.1f}\")"],"execution_count":0,"outputs":[]}]}